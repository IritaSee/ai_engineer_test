{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5: Make simple face recognition with Haar Cascade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install and import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate dataset:\n",
    "Here I captured around 60 frames of my face using my webcam. I added a code to use photo as dataset input. I included one of my fellow's photo (using his concern), then use those as dataset alongside my webcam capture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load face detector configurations (uses haar cascade face detection)\n",
    "detector = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "faceID = 0 #each person has their own ID\n",
    "\n",
    "dataset_dir = './images'\n",
    "\n",
    "if not os.path.exists(dataset_dir):\n",
    "    os.makedirs(dataset_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved 1frame for faceID 0\n",
      "saved 2frame for faceID 0\n",
      "saved 3frame for faceID 0\n",
      "saved 4frame for faceID 0\n",
      "saved 5frame for faceID 0\n",
      "saved 6frame for faceID 0\n",
      "saved 7frame for faceID 0\n",
      "saved 8frame for faceID 0\n",
      "saved 9frame for faceID 0\n",
      "saved 10frame for faceID 0\n",
      "saved 11frame for faceID 0\n",
      "saved 12frame for faceID 0\n",
      "saved 13frame for faceID 0\n",
      "saved 14frame for faceID 0\n",
      "saved 15frame for faceID 0\n",
      "saved 16frame for faceID 0\n",
      "saved 17frame for faceID 0\n",
      "saved 18frame for faceID 0\n",
      "saved 19frame for faceID 0\n",
      "saved 20frame for faceID 0\n",
      "saved 21frame for faceID 0\n",
      "saved 22frame for faceID 0\n",
      "saved 23frame for faceID 0\n",
      "saved 24frame for faceID 0\n",
      "saved 25frame for faceID 0\n",
      "saved 26frame for faceID 0\n",
      "saved 27frame for faceID 0\n",
      "saved 28frame for faceID 0\n",
      "saved 29frame for faceID 0\n",
      "saved 30frame for faceID 0\n",
      "saved 31frame for faceID 0\n",
      "saved 32frame for faceID 0\n",
      "saved 33frame for faceID 0\n",
      "saved 34frame for faceID 0\n",
      "saved 35frame for faceID 0\n",
      "saved 36frame for faceID 0\n",
      "saved 37frame for faceID 0\n",
      "saved 38frame for faceID 0\n",
      "saved 39frame for faceID 0\n",
      "saved 40frame for faceID 0\n",
      "saved 41frame for faceID 0\n",
      "saved 42frame for faceID 0\n",
      "saved 43frame for faceID 0\n",
      "saved 44frame for faceID 0\n",
      "saved 45frame for faceID 0\n",
      "saved 46frame for faceID 0\n",
      "saved 47frame for faceID 0\n",
      "saved 48frame for faceID 0\n",
      "saved 49frame for faceID 0\n",
      "saved 50frame for faceID 0\n",
      "saved 51frame for faceID 0\n",
      "saved 52frame for faceID 0\n",
      "saved 53frame for faceID 0\n",
      "saved 54frame for faceID 0\n",
      "saved 55frame for faceID 0\n",
      "saved 56frame for faceID 0\n",
      "saved 57frame for faceID 0\n",
      "saved 58frame for faceID 0\n",
      "saved 59frame for faceID 0\n",
      "saved 60frame for faceID 0\n"
     ]
    }
   ],
   "source": [
    "#using webcam to capture 60 frames of images\n",
    "camera = cv2.VideoCapture(0)\n",
    "img_count = 0\n",
    "\n",
    "while (1>0):\n",
    "    _, image = camera.read()\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    face = detector.detectMultiScale(image)\n",
    "    for (x,y,w,h) in face:\n",
    "         # Crop the image \n",
    "        cv2.rectangle(image, (x,y), (x+w,y+h), (255,0,0), 2)\n",
    "        img_count = img_count + 1\n",
    "        # Save the captured image to dataset_dir folder\n",
    "        cv2.imwrite(dataset_dir+\"/faceID.\" + str(faceID) + '.' + str(img_count) + \".jpg\", image[y:y+h,x:x+w])\n",
    "        print(\"saved \"+str(img_count)+\"frame for faceID \"+str(faceID))\n",
    "        # Display the video frame, with bounded rectangle on the person's face\n",
    "        cv2.imshow('frame', image)\n",
    "\n",
    "    if img_count == 60:\n",
    "        break\n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved 1frame for faceID 1\n",
      "saved 2frame for faceID 1\n",
      "saved 3frame for faceID 1\n",
      "saved 4frame for faceID 1\n",
      "saved 5frame for faceID 1\n",
      "saved 6frame for faceID 1\n",
      "saved 7frame for faceID 1\n",
      "saved 8frame for faceID 1\n",
      "saved 9frame for faceID 1\n",
      "saved 10frame for faceID 1\n",
      "saved 11frame for faceID 1\n",
      "saved 12frame for faceID 1\n",
      "saved 13frame for faceID 1\n",
      "saved 14frame for faceID 1\n",
      "saved 15frame for faceID 1\n",
      "saved 16frame for faceID 1\n",
      "saved 17frame for faceID 1\n",
      "saved 18frame for faceID 1\n",
      "saved 19frame for faceID 1\n",
      "saved 20frame for faceID 1\n",
      "saved 21frame for faceID 1\n",
      "saved 22frame for faceID 1\n",
      "saved 23frame for faceID 1\n",
      "saved 24frame for faceID 1\n",
      "saved 25frame for faceID 1\n",
      "saved 26frame for faceID 1\n",
      "saved 27frame for faceID 1\n",
      "saved 28frame for faceID 1\n",
      "saved 29frame for faceID 1\n",
      "saved 30frame for faceID 1\n",
      "saved 31frame for faceID 1\n",
      "saved 32frame for faceID 1\n",
      "saved 33frame for faceID 1\n",
      "saved 34frame for faceID 1\n",
      "saved 35frame for faceID 1\n",
      "saved 36frame for faceID 1\n",
      "saved 37frame for faceID 1\n",
      "saved 38frame for faceID 1\n",
      "saved 39frame for faceID 1\n",
      "saved 40frame for faceID 1\n",
      "saved 41frame for faceID 1\n",
      "saved 42frame for faceID 1\n",
      "saved 43frame for faceID 1\n",
      "saved 44frame for faceID 1\n",
      "saved 45frame for faceID 1\n",
      "saved 46frame for faceID 1\n",
      "saved 47frame for faceID 1\n",
      "saved 48frame for faceID 1\n",
      "saved 49frame for faceID 1\n",
      "saved 50frame for faceID 1\n",
      "saved 51frame for faceID 1\n",
      "saved 52frame for faceID 1\n",
      "saved 53frame for faceID 1\n",
      "saved 54frame for faceID 1\n",
      "saved 55frame for faceID 1\n",
      "saved 56frame for faceID 1\n",
      "saved 57frame for faceID 1\n",
      "saved 58frame for faceID 1\n",
      "saved 59frame for faceID 1\n",
      "saved 60frame for faceID 1\n"
     ]
    }
   ],
   "source": [
    "faceID=1\n",
    "img_count = 0\n",
    "sample = './sample.jpeg'\n",
    "while (1>0):\n",
    "    image = Image.open(sample).convert('L')\n",
    "    image = np.array(image)\n",
    "    face = detector.detectMultiScale(image)\n",
    "    for (x,y,w,h) in face:\n",
    "         # Crop the image \n",
    "        cv2.rectangle(image, (x,y), (x+w,y+h), (255,0,0), 2)\n",
    "        img_count = img_count + 1\n",
    "        # Save the captured image to dataset_dir folder\n",
    "        cv2.imwrite(dataset_dir+\"/faceID.\" + str(faceID) + '.' + str(img_count) + \".jpg\", image[y:y+h,x:x+w])\n",
    "        print(\"saved \"+str(img_count)+\"frame for faceID \"+str(faceID))\n",
    "        # Display the video frame, with bounded rectangle on the person's face\n",
    "        cv2.imshow('frame', image)\n",
    "\n",
    "    if img_count == 60:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build face recognition\n",
    "After we have the face (or faces of people we are going to detect), we build a model to recognise a human face and differentiate person according to their face. We are using LBPH Face Recogniser from opencv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "recogniser = cv2.face.LBPHFaceRecognizer_create()\n",
    "images_name = os.listdir(dataset_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create face-id coupling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_sample = []\n",
    "faces_id = []\n",
    "for image_name in images_name:\n",
    "    path = dataset_dir+\"/\"+image_name\n",
    "    image_array = Image.open(path).convert('L')\n",
    "    image_array = np.array(image_array)\n",
    "    person = int(image_name.split('.')[1])\n",
    "    detected_face = detector.detectMultiScale(image_array)\n",
    "    for (x,y,w,h) in detected_face:\n",
    "        faces_sample.append(image_array[y:y+h,x:x+w])\n",
    "        faces_id.append(person)\n",
    "faces_id = np.array(faces_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train recogniser using faces_sample and faces_id, then save the training result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "recogniser.train(faces_sample,faces_id)\n",
    "recogniser.save('./recogniser.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test face recognition\n",
    "Here, we will add some code to turn webcam on, detect some face, and recognise different people in the webcam! Unfortunately, the webcam promt does not work on a jupyter notebook. So let's create a regular python script for this!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "220b59355a8dadb4ba3bf77e4f9773cad1e54b32290f811d9d316f35385cbe26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
